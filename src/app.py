from module.img_segmentation.img_seg import DetectronSegmentation
from module.text_detect.text_det import TextDetection
from module.text_recog.text_recognition import VietOCRPrediction
from module.img_cls.image_classification import EfficientNetClassification
from module.text_cls.PhoBert_prediction import PhoBertPrediction
from module.text_cls.svm_cls import SVMClassifier
import streamlit as st
from PIL import Image, ImageDraw
import cv2
import numpy as np
import pandas as pd
from utils import *

st.markdown("""
    <style>
    .stButton > button {
        width: 100%;
        background-color: #4CAF50; /* M√†u xanh */
        color: white; /* M√†u ch·ªØ tr·∫Øng */
    }
    </style>
    """, unsafe_allow_html=True)



# Ti√™u ƒë·ªÅ c·ªßa ·ª©ng d·ª•ng
st.title("üéØTr√≠ch xu·∫•t th√¥ng tin t·ª´ ho√° ƒë∆°n")
st.sidebar.header("üì§T√πy ch·ªçn t·∫£i h√¨nh ·∫£nh l√™n")

uploaded_file = st.sidebar.file_uploader("Ch·ªçn h√¨nh ·∫£nh ƒë·ªÉ t·∫£i l√™n:", type=["jpg", "jpeg", "png"])

# Hi·ªÉn th·ªã n·ªôi dung d·ª±a tr√™n vi·ªác t·∫£i l√™n h√¨nh ·∫£nh
if uploaded_file is not None:
    # ƒê·ªçc h√¨nh ·∫£nh v√† hi·ªÉn th·ªã
    image = Image.open(uploaded_file)
    st.sidebar.image(image, caption="H√¨nh ·∫£nh ƒë√£ t·∫£i l√™n.", use_container_width=True)

# Tao buton send
send_flag = False
if st.sidebar.button('Send'):
    send_flag = True

# T·∫°o c√°c tab
tabs = st.tabs(["üî•Phase 1", "üíßPhase 2", "‚ö°Phase 3"])

# N·ªôi dung c·ªßa Tab 1
with tabs[0]:
    done_task1 = False
    detectron = DetectronSegmentation(
        config_path='/media/icnlab/Data/Manh/OCR/Documentation/Detectron2_Segmentation/config.yml',
        weight_path= '/media/icnlab/Data/Manh/OCR/src/module/img_segmentation/weights/model_final.pth',
        device='cuda'
    )
    st.header("Xo√° background ·∫£nh üî®")
    with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
        if send_flag:
            img = np.array(image)
            img = remove_background(detectron, img)
            st.image(img, caption="ƒê√£ xo√° background ·∫£nh.", use_container_width=True,  width=50)
            st.success("X·ª≠ l√Ω ho√†n t·∫•t!")
            done_task1 = True
            
# N·ªôi dung c·ªßa Tab 2
with tabs[1]:
    st.header("Xoay ·∫£nh v√† ph√°t hi·ªán c√°c box üé®")
    text_detect_model = TextDetection(device='cuda')
    flip_model = EfficientNetClassification(
        # weight_path = 'weights/weightinvoiced_weight.pth',
    )
    with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
        done_task2 = False
        if done_task1:
            # Replace
            boxes = text_detect_model.predict_boxes(img)
            # img = rotate_and_flip(flip_model, img, boxes)
            # boxes = text_detect_model.predict_boxes(img)

            draw_boxes(boxes, img, save_path = None)
            st.image(img, caption="Xoay ·∫£nh v√† ph√°t hi·ªán c√°c box.", use_container_width=True,  width=50)
            st.success("X·ª≠ l√Ω ho√†n t·∫•t!")
            done_task2 = True

# N·ªôi dung c·ªßa Tab 3
with tabs[2]:
    st.header("Ph√¢n lo·∫°i v√† hi·ªÉn th·ªã üö©")
    
    with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
        ocr_model  = VietOCRPrediction(
            config_name= 'vgg_transformer',
            weight_path= '/media/icnlab/Data/Manh/OCR/Documentation/Text_Recognize/weights/transformerocr.pth', 
        )
        # Load model PhoBert
        bert_model = PhoBertPrediction(weight_path= '/media/icnlab/Data/Manh/OCR/Documentation/Text_Classification/weights/model_best_valoss.pt')

        # Load model SVM Classification
        svm_clf = SVMClassifier(
            tfidf_path='/media/icnlab/Data/Manh/OCR/Documentation/Text_Classification/svm_model/model_vectorizer_tfidf.pkl',
            svm_path= '/media/icnlab/Data/Manh/OCR/Documentation/Text_Classification/svm_model/svm_classifier_model.pkl'
        )
        if done_task2:
            list_text = text_recog_vietocr(ocr_model, boxes, img) # return list of text
            seller, address, timestamp, totalcost = text_classification(
                phobert_model=bert_model,
                svm_model=svm_clf,
                list_text = list_text,
                boxes=boxes
            )

            text_seller, text_address, text_timestamp, text_totalcost = '', '', '', ''
            for seller_box in seller:
                text_seller += seller_box['text'] +  ' '
            for address_box in address:
                text_address += address_box['text'] + ' '
            for timestamp_box in timestamp:
                text_timestamp += timestamp_box['text'] + ' '
            for totalcost_box in totalcost:
                text_totalcost += totalcost_box['text'] + ' '
            data = {
                'SELLER': [text_seller], 
                'ADDRESS': [text_address],
                'TIMESTAMP': [text_timestamp],
                'TOTALCOST': [text_totalcost]
            }
            df = pd.DataFrame(data)
            st.table(df)
            img = visualize_image1(seller, address, timestamp, totalcost, img)
            st.image(img, caption="Ph√¢n lo·∫°i v√† hi·ªÉn th·ªã.", use_container_width=True,  width=50)
            st.success("X·ª≠ l√Ω ho√†n t·∫•t!")
 